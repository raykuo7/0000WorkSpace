{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raykuo7\\AppData\\Local\\Temp\\ipykernel_19508\\2707019372.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('fan_corner_detector_1126.pth'))  # 加载模型参数\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNNPointDetector(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=4096, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class CNNPointDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNPointDetector, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)  # Output (x, y) coordinates\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x), 2))\n",
    "        x = x.view(-1, 64 * 8 * 8)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = CNNPointDetector()\n",
    "# 初始化模型\n",
    "model = CNNPointDetector()\n",
    "model.load_state_dict(torch.load('fan_corner_detector_1126.pth'))  # 加载模型参数\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class FanDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_size=64):\n",
    "        self.annotations = pd.read_csv(annotations_file)\n",
    "        self.img_size = img_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.annotations.iloc[idx, 0]\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, (self.img_size, self.img_size)) / 2047.0  # Resize and normalize\n",
    "        image = image.reshape(1, self.img_size, self.img_size)  # Reshape for CNN input\n",
    "\n",
    "        # Label: x and y coordinates of the corner\n",
    "        label = self.annotations.iloc[idx, 1:3].values.astype(np.float32)\n",
    "        return torch.tensor(image, dtype=torch.float32), torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "# 使用自己的标注文件\n",
    "dataset = FanDataset('selected_points_1126.csv')\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 35067.9480 about 20.0 min left\n",
      "Epoch [2/30], Loss: 19434.7501 about 19.333333333333332 min left\n",
      "Epoch [3/30], Loss: 11264.8167 about 18.666666666666668 min left\n",
      "Epoch [4/30], Loss: 8270.8713 about 18.0 min left\n",
      "Epoch [5/30], Loss: 5529.9567 about 17.333333333333332 min left\n",
      "Epoch [6/30], Loss: 3399.3801 about 16.666666666666668 min left\n",
      "Epoch [7/30], Loss: 1796.2812 about 16.0 min left\n",
      "Epoch [8/30], Loss: 1460.7927 about 15.333333333333334 min left\n",
      "Epoch [9/30], Loss: 865.1829 about 14.666666666666666 min left\n",
      "Epoch [10/30], Loss: 903.0855 about 14.0 min left\n",
      "Epoch [11/30], Loss: 634.2906 about 13.333333333333334 min left\n",
      "Epoch [12/30], Loss: 666.7213 about 12.666666666666666 min left\n",
      "Epoch [13/30], Loss: 583.2566 about 12.0 min left\n",
      "Epoch [14/30], Loss: 567.5652 about 11.333333333333334 min left\n",
      "Epoch [15/30], Loss: 537.0681 about 10.666666666666666 min left\n",
      "Epoch [16/30], Loss: 547.7424 about 10.0 min left\n",
      "Epoch [17/30], Loss: 537.6191 about 9.333333333333334 min left\n",
      "Epoch [18/30], Loss: 536.3920 about 8.666666666666666 min left\n",
      "Epoch [19/30], Loss: 514.2590 about 8.0 min left\n",
      "Epoch [20/30], Loss: 476.2529 about 7.333333333333333 min left\n",
      "Epoch [21/30], Loss: 506.7847 about 6.666666666666667 min left\n",
      "Epoch [22/30], Loss: 508.7119 about 6.0 min left\n",
      "Epoch [23/30], Loss: 497.1515 about 5.333333333333333 min left\n",
      "Epoch [24/30], Loss: 497.1679 about 4.666666666666667 min left\n",
      "Epoch [25/30], Loss: 525.9620 about 4.0 min left\n",
      "Epoch [26/30], Loss: 508.6790 about 3.3333333333333335 min left\n",
      "Epoch [27/30], Loss: 498.9777 about 2.6666666666666665 min left\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\", 'about',(num_epochs-epoch)/1.5,'min left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './fan_corner_detector_1127.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvdi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
