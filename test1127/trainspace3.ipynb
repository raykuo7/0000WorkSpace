{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raykuo7\\AppData\\Local\\Temp\\ipykernel_24144\\985769453.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('fan_corner3_detector_1127.pth'))  # 加载模型参数\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNNPointDetector(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=4096, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class CNNPointDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNPointDetector, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)  # Output (x, y) coordinates\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x), 2))\n",
    "        x = x.view(-1, 64 * 8 * 8)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = CNNPointDetector()\n",
    "# 初始化模型\n",
    "model = CNNPointDetector()\n",
    "model.load_state_dict(torch.load('fan_corner3_detector_1127.pth'))  # 加载模型参数\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# newstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class FanDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_size=64):\n",
    "        self.annotations = pd.read_csv(annotations_file)\n",
    "        self.img_size = img_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.annotations.iloc[idx, 0]\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, (self.img_size, self.img_size)) / 2047.0  # Resize and normalize\n",
    "        image = image.reshape(1, self.img_size, self.img_size)  # Reshape for CNN input\n",
    "\n",
    "        # Label: x and y coordinates of the corner\n",
    "        label = self.annotations.iloc[idx, 1:3].values.astype(np.float32)\n",
    "        return torch.tensor(image, dtype=torch.float32), torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "# 使用自己的标注文件\n",
    "dataset = FanDataset('selected_points3_1127.csv')\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNPointDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNPointDetector, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)  # Output (x, y) coordinates\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x), 2))\n",
    "        x = x.view(-1, 64 * 8 * 8)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = CNNPointDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/450], Loss: 6793287.4000 about 450.0 min left\n",
      "Epoch [2/450], Loss: 6773667.7000 about 449.0 min left\n",
      "Epoch [3/450], Loss: 6710782.5000 about 448.0 min left\n",
      "Epoch [4/450], Loss: 6510072.0000 about 447.0 min left\n",
      "Epoch [5/450], Loss: 5983661.8000 about 446.0 min left\n",
      "Epoch [6/450], Loss: 4872821.0000 about 445.0 min left\n",
      "Epoch [7/450], Loss: 2966168.9000 about 444.0 min left\n",
      "Epoch [8/450], Loss: 1135837.0625 about 443.0 min left\n",
      "Epoch [9/450], Loss: 1185184.9250 about 442.0 min left\n",
      "Epoch [10/450], Loss: 877017.4250 about 441.0 min left\n",
      "Epoch [11/450], Loss: 656308.9500 about 440.0 min left\n",
      "Epoch [12/450], Loss: 758851.4875 about 439.0 min left\n",
      "Epoch [13/450], Loss: 681887.2500 about 438.0 min left\n",
      "Epoch [14/450], Loss: 676425.7750 about 437.0 min left\n",
      "Epoch [15/450], Loss: 661114.1125 about 436.0 min left\n",
      "Epoch [16/450], Loss: 633438.6000 about 435.0 min left\n",
      "Epoch [17/450], Loss: 639163.0750 about 434.0 min left\n",
      "Epoch [18/450], Loss: 631184.5250 about 433.0 min left\n",
      "Epoch [19/450], Loss: 632953.7625 about 432.0 min left\n",
      "Epoch [20/450], Loss: 635129.7125 about 431.0 min left\n",
      "Epoch [21/450], Loss: 632698.4875 about 430.0 min left\n",
      "Epoch [22/450], Loss: 633108.1937 about 429.0 min left\n",
      "Epoch [23/450], Loss: 628518.8375 about 428.0 min left\n",
      "Epoch [24/450], Loss: 629933.1750 about 427.0 min left\n",
      "Epoch [25/450], Loss: 628485.4500 about 426.0 min left\n",
      "Epoch [26/450], Loss: 636210.1625 about 425.0 min left\n",
      "Epoch [27/450], Loss: 631909.6125 about 424.0 min left\n",
      "Epoch [28/450], Loss: 626763.4250 about 423.0 min left\n",
      "Epoch [29/450], Loss: 627742.1875 about 422.0 min left\n",
      "Epoch [30/450], Loss: 626828.3125 about 421.0 min left\n",
      "Epoch [31/450], Loss: 629373.1375 about 420.0 min left\n",
      "Epoch [32/450], Loss: 630182.7125 about 419.0 min left\n",
      "Epoch [33/450], Loss: 626524.9250 about 418.0 min left\n",
      "Epoch [34/450], Loss: 626188.3625 about 417.0 min left\n",
      "Epoch [35/450], Loss: 627074.3812 about 416.0 min left\n",
      "Epoch [36/450], Loss: 626803.5375 about 415.0 min left\n",
      "Epoch [37/450], Loss: 625089.0250 about 414.0 min left\n",
      "Epoch [38/450], Loss: 622984.6875 about 413.0 min left\n",
      "Epoch [39/450], Loss: 622700.3750 about 412.0 min left\n",
      "Epoch [40/450], Loss: 623369.3375 about 411.0 min left\n",
      "Epoch [41/450], Loss: 621652.1125 about 410.0 min left\n",
      "Epoch [42/450], Loss: 621285.6562 about 409.0 min left\n",
      "Epoch [43/450], Loss: 623668.9187 about 408.0 min left\n",
      "Epoch [44/450], Loss: 625311.5875 about 407.0 min left\n",
      "Epoch [45/450], Loss: 621223.4000 about 406.0 min left\n",
      "Epoch [46/450], Loss: 620776.3000 about 405.0 min left\n",
      "Epoch [47/450], Loss: 620617.2937 about 404.0 min left\n",
      "Epoch [48/450], Loss: 621144.5375 about 403.0 min left\n",
      "Epoch [49/450], Loss: 624687.9000 about 402.0 min left\n",
      "Epoch [50/450], Loss: 618782.6500 about 401.0 min left\n",
      "Epoch [51/450], Loss: 619823.0437 about 400.0 min left\n",
      "Epoch [52/450], Loss: 623162.2500 about 399.0 min left\n",
      "Epoch [53/450], Loss: 618225.1625 about 398.0 min left\n",
      "Epoch [54/450], Loss: 621437.2625 about 397.0 min left\n",
      "Epoch [55/450], Loss: 617356.1375 about 396.0 min left\n",
      "Epoch [56/450], Loss: 619234.9875 about 395.0 min left\n",
      "Epoch [57/450], Loss: 618011.6750 about 394.0 min left\n",
      "Epoch [58/450], Loss: 620881.2750 about 393.0 min left\n",
      "Epoch [59/450], Loss: 618248.8625 about 392.0 min left\n",
      "Epoch [60/450], Loss: 616719.8938 about 391.0 min left\n",
      "Epoch [61/450], Loss: 615891.4375 about 390.0 min left\n",
      "Epoch [62/450], Loss: 618270.6625 about 389.0 min left\n",
      "Epoch [63/450], Loss: 618850.4750 about 388.0 min left\n",
      "Epoch [64/450], Loss: 616819.0437 about 387.0 min left\n",
      "Epoch [65/450], Loss: 615244.8688 about 386.0 min left\n",
      "Epoch [66/450], Loss: 616892.0500 about 385.0 min left\n",
      "Epoch [67/450], Loss: 618596.9750 about 384.0 min left\n",
      "Epoch [68/450], Loss: 615527.9750 about 383.0 min left\n",
      "Epoch [69/450], Loss: 617225.2125 about 382.0 min left\n",
      "Epoch [70/450], Loss: 615472.3000 about 381.0 min left\n",
      "Epoch [71/450], Loss: 615073.4750 about 380.0 min left\n",
      "Epoch [72/450], Loss: 614542.5125 about 379.0 min left\n",
      "Epoch [73/450], Loss: 613147.4187 about 378.0 min left\n",
      "Epoch [74/450], Loss: 613963.7375 about 377.0 min left\n",
      "Epoch [75/450], Loss: 613528.1188 about 376.0 min left\n",
      "Epoch [76/450], Loss: 614666.4313 about 375.0 min left\n",
      "Epoch [77/450], Loss: 613871.8750 about 374.0 min left\n",
      "Epoch [78/450], Loss: 615937.0750 about 373.0 min left\n",
      "Epoch [79/450], Loss: 613291.5625 about 372.0 min left\n",
      "Epoch [80/450], Loss: 616971.2250 about 371.0 min left\n",
      "Epoch [81/450], Loss: 613855.0563 about 370.0 min left\n",
      "Epoch [82/450], Loss: 613786.1750 about 369.0 min left\n",
      "Epoch [83/450], Loss: 611640.0375 about 368.0 min left\n",
      "Epoch [84/450], Loss: 612468.3125 about 367.0 min left\n",
      "Epoch [85/450], Loss: 611238.8313 about 366.0 min left\n",
      "Epoch [86/450], Loss: 611143.4500 about 365.0 min left\n",
      "Epoch [87/450], Loss: 613329.7125 about 364.0 min left\n",
      "Epoch [88/450], Loss: 610539.8000 about 363.0 min left\n",
      "Epoch [89/450], Loss: 613686.9875 about 362.0 min left\n",
      "Epoch [90/450], Loss: 610829.1625 about 361.0 min left\n",
      "Epoch [91/450], Loss: 609996.5000 about 360.0 min left\n",
      "Epoch [92/450], Loss: 612441.2438 about 359.0 min left\n",
      "Epoch [93/450], Loss: 610578.1750 about 358.0 min left\n",
      "Epoch [94/450], Loss: 607603.1000 about 357.0 min left\n",
      "Epoch [95/450], Loss: 607856.8250 about 356.0 min left\n",
      "Epoch [96/450], Loss: 612424.1250 about 355.0 min left\n",
      "Epoch [97/450], Loss: 607138.1250 about 354.0 min left\n",
      "Epoch [98/450], Loss: 615891.8875 about 353.0 min left\n",
      "Epoch [99/450], Loss: 606908.2500 about 352.0 min left\n",
      "Epoch [100/450], Loss: 605452.5625 about 351.0 min left\n",
      "Epoch [101/450], Loss: 607599.5938 about 350.0 min left\n",
      "Epoch [102/450], Loss: 612219.7375 about 349.0 min left\n",
      "Epoch [103/450], Loss: 607319.5500 about 348.0 min left\n",
      "Epoch [104/450], Loss: 610062.2750 about 347.0 min left\n",
      "Epoch [105/450], Loss: 605177.8625 about 346.0 min left\n",
      "Epoch [106/450], Loss: 603143.8625 about 345.0 min left\n",
      "Epoch [107/450], Loss: 608150.5375 about 344.0 min left\n",
      "Epoch [108/450], Loss: 605406.7500 about 343.0 min left\n",
      "Epoch [109/450], Loss: 606047.0625 about 342.0 min left\n",
      "Epoch [110/450], Loss: 603515.2250 about 341.0 min left\n",
      "Epoch [111/450], Loss: 601207.4000 about 340.0 min left\n",
      "Epoch [112/450], Loss: 603581.7250 about 339.0 min left\n",
      "Epoch [113/450], Loss: 599523.4125 about 338.0 min left\n",
      "Epoch [114/450], Loss: 600475.6750 about 337.0 min left\n",
      "Epoch [115/450], Loss: 600470.4812 about 336.0 min left\n",
      "Epoch [116/450], Loss: 599333.5000 about 335.0 min left\n",
      "Epoch [117/450], Loss: 600832.3875 about 334.0 min left\n",
      "Epoch [118/450], Loss: 596036.7500 about 333.0 min left\n",
      "Epoch [119/450], Loss: 604874.3313 about 332.0 min left\n",
      "Epoch [120/450], Loss: 597836.9563 about 331.0 min left\n",
      "Epoch [121/450], Loss: 596463.5938 about 330.0 min left\n",
      "Epoch [122/450], Loss: 602010.3625 about 329.0 min left\n",
      "Epoch [123/450], Loss: 594763.5875 about 328.0 min left\n",
      "Epoch [124/450], Loss: 599272.3187 about 327.0 min left\n",
      "Epoch [125/450], Loss: 593037.1062 about 326.0 min left\n",
      "Epoch [126/450], Loss: 593363.0000 about 325.0 min left\n",
      "Epoch [127/450], Loss: 593657.5813 about 324.0 min left\n",
      "Epoch [128/450], Loss: 593046.5750 about 323.0 min left\n",
      "Epoch [129/450], Loss: 590197.6375 about 322.0 min left\n",
      "Epoch [130/450], Loss: 591329.0375 about 321.0 min left\n",
      "Epoch [131/450], Loss: 590303.1813 about 320.0 min left\n",
      "Epoch [132/450], Loss: 589141.5250 about 319.0 min left\n",
      "Epoch [133/450], Loss: 587715.1250 about 318.0 min left\n",
      "Epoch [134/450], Loss: 589988.2250 about 317.0 min left\n",
      "Epoch [135/450], Loss: 588484.0188 about 316.0 min left\n",
      "Epoch [136/450], Loss: 587620.6188 about 315.0 min left\n",
      "Epoch [137/450], Loss: 587224.9688 about 314.0 min left\n",
      "Epoch [138/450], Loss: 586006.9000 about 313.0 min left\n",
      "Epoch [139/450], Loss: 593249.4875 about 312.0 min left\n",
      "Epoch [140/450], Loss: 588467.2312 about 311.0 min left\n",
      "Epoch [141/450], Loss: 582524.2500 about 310.0 min left\n",
      "Epoch [142/450], Loss: 583853.9625 about 309.0 min left\n",
      "Epoch [143/450], Loss: 580306.7500 about 308.0 min left\n",
      "Epoch [144/450], Loss: 584649.3875 about 307.0 min left\n",
      "Epoch [145/450], Loss: 580254.3125 about 306.0 min left\n",
      "Epoch [146/450], Loss: 581423.2125 about 305.0 min left\n",
      "Epoch [147/450], Loss: 580100.4000 about 304.0 min left\n",
      "Epoch [148/450], Loss: 574803.0750 about 303.0 min left\n",
      "Epoch [149/450], Loss: 575079.3063 about 302.0 min left\n",
      "Epoch [150/450], Loss: 573586.4563 about 301.0 min left\n",
      "Epoch [151/450], Loss: 573565.1188 about 300.0 min left\n",
      "Epoch [152/450], Loss: 571630.7250 about 299.0 min left\n",
      "Epoch [153/450], Loss: 574215.8625 about 298.0 min left\n",
      "Epoch [154/450], Loss: 574969.1250 about 297.0 min left\n",
      "Epoch [155/450], Loss: 568266.3250 about 296.0 min left\n",
      "Epoch [156/450], Loss: 570356.6813 about 295.0 min left\n",
      "Epoch [157/450], Loss: 576079.2625 about 294.0 min left\n",
      "Epoch [158/450], Loss: 567415.2750 about 293.0 min left\n",
      "Epoch [159/450], Loss: 567377.9938 about 292.0 min left\n",
      "Epoch [160/450], Loss: 568832.7625 about 291.0 min left\n",
      "Epoch [161/450], Loss: 577204.0437 about 290.0 min left\n",
      "Epoch [162/450], Loss: 561030.8125 about 289.0 min left\n",
      "Epoch [163/450], Loss: 573731.8000 about 288.0 min left\n",
      "Epoch [164/450], Loss: 562799.7125 about 287.0 min left\n",
      "Epoch [165/450], Loss: 565710.2125 about 286.0 min left\n",
      "Epoch [166/450], Loss: 561517.5000 about 285.0 min left\n",
      "Epoch [167/450], Loss: 555922.9688 about 284.0 min left\n",
      "Epoch [168/450], Loss: 556572.7125 about 283.0 min left\n",
      "Epoch [169/450], Loss: 558417.2500 about 282.0 min left\n",
      "Epoch [170/450], Loss: 554661.1687 about 281.0 min left\n",
      "Epoch [171/450], Loss: 552664.8375 about 280.0 min left\n",
      "Epoch [172/450], Loss: 548863.9062 about 279.0 min left\n",
      "Epoch [173/450], Loss: 552030.2000 about 278.0 min left\n",
      "Epoch [174/450], Loss: 552219.3375 about 277.0 min left\n",
      "Epoch [175/450], Loss: 548570.2188 about 276.0 min left\n",
      "Epoch [176/450], Loss: 545973.9500 about 275.0 min left\n",
      "Epoch [177/450], Loss: 545790.8625 about 274.0 min left\n",
      "Epoch [178/450], Loss: 541753.6875 about 273.0 min left\n",
      "Epoch [179/450], Loss: 540195.7937 about 272.0 min left\n",
      "Epoch [180/450], Loss: 538720.2125 about 271.0 min left\n",
      "Epoch [181/450], Loss: 538417.1250 about 270.0 min left\n",
      "Epoch [182/450], Loss: 535450.2188 about 269.0 min left\n",
      "Epoch [183/450], Loss: 534354.7688 about 268.0 min left\n",
      "Epoch [184/450], Loss: 530774.4000 about 267.0 min left\n",
      "Epoch [185/450], Loss: 532210.1062 about 266.0 min left\n",
      "Epoch [186/450], Loss: 530258.3500 about 265.0 min left\n",
      "Epoch [187/450], Loss: 527899.7438 about 264.0 min left\n",
      "Epoch [188/450], Loss: 528083.5875 about 263.0 min left\n",
      "Epoch [189/450], Loss: 523839.5062 about 262.0 min left\n",
      "Epoch [190/450], Loss: 522477.2687 about 261.0 min left\n",
      "Epoch [191/450], Loss: 520930.2062 about 260.0 min left\n",
      "Epoch [192/450], Loss: 517759.7000 about 259.0 min left\n",
      "Epoch [193/450], Loss: 516441.7000 about 258.0 min left\n",
      "Epoch [194/450], Loss: 513935.0062 about 257.0 min left\n",
      "Epoch [195/450], Loss: 511469.5438 about 256.0 min left\n",
      "Epoch [196/450], Loss: 507867.8125 about 255.0 min left\n",
      "Epoch [197/450], Loss: 508358.4125 about 254.0 min left\n",
      "Epoch [198/450], Loss: 503837.7188 about 253.0 min left\n",
      "Epoch [199/450], Loss: 501392.0062 about 252.0 min left\n",
      "Epoch [200/450], Loss: 498912.6750 about 251.0 min left\n",
      "Epoch [201/450], Loss: 498002.5750 about 250.0 min left\n",
      "Epoch [202/450], Loss: 491168.1813 about 249.0 min left\n",
      "Epoch [203/450], Loss: 489280.8000 about 248.0 min left\n",
      "Epoch [204/450], Loss: 487046.4375 about 247.0 min left\n",
      "Epoch [205/450], Loss: 481967.4375 about 246.0 min left\n",
      "Epoch [206/450], Loss: 479750.2125 about 245.0 min left\n",
      "Epoch [207/450], Loss: 479034.4688 about 244.0 min left\n",
      "Epoch [208/450], Loss: 474853.8000 about 243.0 min left\n",
      "Epoch [209/450], Loss: 470338.7438 about 242.0 min left\n",
      "Epoch [210/450], Loss: 470722.8187 about 241.0 min left\n",
      "Epoch [211/450], Loss: 465689.7188 about 240.0 min left\n",
      "Epoch [212/450], Loss: 462500.7938 about 239.0 min left\n",
      "Epoch [213/450], Loss: 459400.1188 about 238.0 min left\n",
      "Epoch [214/450], Loss: 458078.8375 about 237.0 min left\n",
      "Epoch [215/450], Loss: 458828.5187 about 236.0 min left\n",
      "Epoch [216/450], Loss: 453530.5750 about 235.0 min left\n",
      "Epoch [217/450], Loss: 453548.7375 about 234.0 min left\n",
      "Epoch [218/450], Loss: 453708.2250 about 233.0 min left\n",
      "Epoch [219/450], Loss: 451619.5563 about 232.0 min left\n",
      "Epoch [220/450], Loss: 452569.0625 about 231.0 min left\n",
      "Epoch [221/450], Loss: 448529.9813 about 230.0 min left\n",
      "Epoch [222/450], Loss: 448676.2938 about 229.0 min left\n",
      "Epoch [223/450], Loss: 445835.9250 about 228.0 min left\n",
      "Epoch [224/450], Loss: 445069.9250 about 227.0 min left\n",
      "Epoch [225/450], Loss: 443694.6063 about 226.0 min left\n",
      "Epoch [226/450], Loss: 442906.2625 about 225.0 min left\n",
      "Epoch [227/450], Loss: 447191.7313 about 224.0 min left\n",
      "Epoch [228/450], Loss: 442169.8812 about 223.0 min left\n",
      "Epoch [229/450], Loss: 443251.9437 about 222.0 min left\n",
      "Epoch [230/450], Loss: 443614.2625 about 221.0 min left\n",
      "Epoch [231/450], Loss: 444343.9938 about 220.0 min left\n",
      "Epoch [232/450], Loss: 441677.0125 about 219.0 min left\n",
      "Epoch [233/450], Loss: 442001.2625 about 218.0 min left\n",
      "Epoch [234/450], Loss: 439820.4938 about 217.0 min left\n",
      "Epoch [235/450], Loss: 441099.0000 about 216.0 min left\n",
      "Epoch [236/450], Loss: 440924.7875 about 215.0 min left\n",
      "Epoch [237/450], Loss: 438648.4313 about 214.0 min left\n",
      "Epoch [238/450], Loss: 438952.3625 about 213.0 min left\n",
      "Epoch [239/450], Loss: 437962.6312 about 212.0 min left\n",
      "Epoch [240/450], Loss: 435671.8000 about 211.0 min left\n",
      "Epoch [241/450], Loss: 438217.2875 about 210.0 min left\n",
      "Epoch [242/450], Loss: 434877.5187 about 209.0 min left\n",
      "Epoch [243/450], Loss: 436085.8563 about 208.0 min left\n",
      "Epoch [244/450], Loss: 438325.5875 about 207.0 min left\n",
      "Epoch [245/450], Loss: 435173.8438 about 206.0 min left\n",
      "Epoch [246/450], Loss: 434275.0812 about 205.0 min left\n",
      "Epoch [247/450], Loss: 435636.6125 about 204.0 min left\n",
      "Epoch [248/450], Loss: 432722.2625 about 203.0 min left\n",
      "Epoch [249/450], Loss: 433028.5312 about 202.0 min left\n",
      "Epoch [250/450], Loss: 431223.9813 about 201.0 min left\n",
      "Epoch [251/450], Loss: 431875.1000 about 200.0 min left\n",
      "Epoch [252/450], Loss: 429590.2625 about 199.0 min left\n",
      "Epoch [253/450], Loss: 431173.7313 about 198.0 min left\n",
      "Epoch [254/450], Loss: 428358.4062 about 197.0 min left\n",
      "Epoch [255/450], Loss: 430114.6937 about 196.0 min left\n",
      "Epoch [256/450], Loss: 436520.9625 about 195.0 min left\n",
      "Epoch [257/450], Loss: 430994.9000 about 194.0 min left\n",
      "Epoch [258/450], Loss: 428516.5938 about 193.0 min left\n",
      "Epoch [259/450], Loss: 430457.6188 about 192.0 min left\n",
      "Epoch [260/450], Loss: 428112.6688 about 191.0 min left\n",
      "Epoch [261/450], Loss: 427347.0125 about 190.0 min left\n",
      "Epoch [262/450], Loss: 426138.2188 about 189.0 min left\n",
      "Epoch [263/450], Loss: 425600.9625 about 188.0 min left\n",
      "Epoch [264/450], Loss: 424086.5187 about 187.0 min left\n",
      "Epoch [265/450], Loss: 424309.3000 about 186.0 min left\n",
      "Epoch [266/450], Loss: 428841.7500 about 185.0 min left\n",
      "Epoch [267/450], Loss: 422411.9125 about 184.0 min left\n",
      "Epoch [268/450], Loss: 423621.3000 about 183.0 min left\n",
      "Epoch [269/450], Loss: 422116.8438 about 182.0 min left\n",
      "Epoch [270/450], Loss: 426379.6437 about 181.0 min left\n",
      "Epoch [271/450], Loss: 424110.6188 about 180.0 min left\n",
      "Epoch [272/450], Loss: 422727.9688 about 179.0 min left\n",
      "Epoch [273/450], Loss: 420770.9875 about 178.0 min left\n",
      "Epoch [274/450], Loss: 421646.0625 about 177.0 min left\n",
      "Epoch [275/450], Loss: 419322.6750 about 176.0 min left\n",
      "Epoch [276/450], Loss: 424879.9813 about 175.0 min left\n",
      "Epoch [277/450], Loss: 421878.2812 about 174.0 min left\n",
      "Epoch [278/450], Loss: 417464.7000 about 173.0 min left\n",
      "Epoch [279/450], Loss: 416626.7438 about 172.0 min left\n",
      "Epoch [280/450], Loss: 415280.6688 about 171.0 min left\n",
      "Epoch [281/450], Loss: 415300.6375 about 170.0 min left\n",
      "Epoch [282/450], Loss: 414714.5625 about 169.0 min left\n",
      "Epoch [283/450], Loss: 414454.3875 about 168.0 min left\n",
      "Epoch [284/450], Loss: 414753.0625 about 167.0 min left\n",
      "Epoch [285/450], Loss: 414038.4813 about 166.0 min left\n",
      "Epoch [286/450], Loss: 417162.7188 about 165.0 min left\n",
      "Epoch [287/450], Loss: 418629.8937 about 164.0 min left\n",
      "Epoch [288/450], Loss: 415247.3438 about 163.0 min left\n",
      "Epoch [289/450], Loss: 414317.5625 about 162.0 min left\n",
      "Epoch [290/450], Loss: 408908.7250 about 161.0 min left\n",
      "Epoch [291/450], Loss: 409578.9062 about 160.0 min left\n",
      "Epoch [292/450], Loss: 415097.4437 about 159.0 min left\n",
      "Epoch [293/450], Loss: 416982.8250 about 158.0 min left\n",
      "Epoch [294/450], Loss: 413494.3688 about 157.0 min left\n",
      "Epoch [295/450], Loss: 416935.4875 about 156.0 min left\n",
      "Epoch [296/450], Loss: 405738.7438 about 155.0 min left\n",
      "Epoch [297/450], Loss: 407885.7562 about 154.0 min left\n",
      "Epoch [298/450], Loss: 409747.7500 about 153.0 min left\n",
      "Epoch [299/450], Loss: 406202.7375 about 152.0 min left\n",
      "Epoch [300/450], Loss: 402925.0875 about 151.0 min left\n",
      "Epoch [301/450], Loss: 405992.3375 about 150.0 min left\n",
      "Epoch [302/450], Loss: 408789.2000 about 149.0 min left\n",
      "Epoch [303/450], Loss: 413702.2938 about 148.0 min left\n",
      "Epoch [304/450], Loss: 402277.7062 about 147.0 min left\n",
      "Epoch [305/450], Loss: 409445.5438 about 146.0 min left\n",
      "Epoch [306/450], Loss: 404429.4750 about 145.0 min left\n",
      "Epoch [307/450], Loss: 408150.6625 about 144.0 min left\n",
      "Epoch [308/450], Loss: 401086.9062 about 143.0 min left\n",
      "Epoch [309/450], Loss: 406564.0438 about 142.0 min left\n",
      "Epoch [310/450], Loss: 400599.3438 about 141.0 min left\n",
      "Epoch [311/450], Loss: 409585.8500 about 140.0 min left\n",
      "Epoch [312/450], Loss: 402232.7875 about 139.0 min left\n",
      "Epoch [313/450], Loss: 402693.0500 about 138.0 min left\n",
      "Epoch [314/450], Loss: 399055.0187 about 137.0 min left\n",
      "Epoch [315/450], Loss: 395989.9188 about 136.0 min left\n",
      "Epoch [316/450], Loss: 397896.8250 about 135.0 min left\n",
      "Epoch [317/450], Loss: 395729.3875 about 134.0 min left\n",
      "Epoch [318/450], Loss: 394737.7313 about 133.0 min left\n",
      "Epoch [319/450], Loss: 395708.7250 about 132.0 min left\n",
      "Epoch [320/450], Loss: 400352.7062 about 131.0 min left\n",
      "Epoch [321/450], Loss: 395378.7625 about 130.0 min left\n",
      "Epoch [322/450], Loss: 393547.4625 about 129.0 min left\n",
      "Epoch [323/450], Loss: 395301.5000 about 128.0 min left\n",
      "Epoch [324/450], Loss: 396161.5062 about 127.0 min left\n",
      "Epoch [325/450], Loss: 393182.9875 about 126.0 min left\n",
      "Epoch [326/450], Loss: 389761.7875 about 125.0 min left\n",
      "Epoch [327/450], Loss: 387873.7250 about 124.0 min left\n",
      "Epoch [328/450], Loss: 388693.9688 about 123.0 min left\n",
      "Epoch [329/450], Loss: 393901.5375 about 122.0 min left\n",
      "Epoch [330/450], Loss: 389201.7438 about 121.0 min left\n",
      "Epoch [331/450], Loss: 391612.0062 about 120.0 min left\n",
      "Epoch [332/450], Loss: 389855.5938 about 119.0 min left\n",
      "Epoch [333/450], Loss: 384192.1437 about 118.0 min left\n",
      "Epoch [334/450], Loss: 384236.7500 about 117.0 min left\n",
      "Epoch [335/450], Loss: 383397.0125 about 116.0 min left\n",
      "Epoch [336/450], Loss: 385955.7062 about 115.0 min left\n",
      "Epoch [337/450], Loss: 381990.2875 about 114.0 min left\n",
      "Epoch [338/450], Loss: 380972.5875 about 113.0 min left\n",
      "Epoch [339/450], Loss: 386258.3063 about 112.0 min left\n",
      "Epoch [340/450], Loss: 387147.8500 about 111.0 min left\n",
      "Epoch [341/450], Loss: 384490.1000 about 110.0 min left\n",
      "Epoch [342/450], Loss: 380818.0812 about 109.0 min left\n",
      "Epoch [343/450], Loss: 378278.1188 about 108.0 min left\n",
      "Epoch [344/450], Loss: 380202.7812 about 107.0 min left\n",
      "Epoch [345/450], Loss: 376521.0750 about 106.0 min left\n",
      "Epoch [346/450], Loss: 373107.4562 about 105.0 min left\n",
      "Epoch [347/450], Loss: 371588.2000 about 104.0 min left\n",
      "Epoch [348/450], Loss: 371441.2000 about 103.0 min left\n",
      "Epoch [349/450], Loss: 370934.4500 about 102.0 min left\n",
      "Epoch [350/450], Loss: 370065.3500 about 101.0 min left\n",
      "Epoch [351/450], Loss: 367512.5375 about 100.0 min left\n",
      "Epoch [352/450], Loss: 364706.4938 about 99.0 min left\n",
      "Epoch [353/450], Loss: 361274.6688 about 98.0 min left\n",
      "Epoch [354/450], Loss: 362795.2500 about 97.0 min left\n",
      "Epoch [355/450], Loss: 360839.1813 about 96.0 min left\n",
      "Epoch [356/450], Loss: 360484.8063 about 95.0 min left\n",
      "Epoch [357/450], Loss: 360710.4875 about 94.0 min left\n",
      "Epoch [358/450], Loss: 352865.1312 about 93.0 min left\n",
      "Epoch [359/450], Loss: 356098.1813 about 92.0 min left\n",
      "Epoch [360/450], Loss: 355151.0438 about 91.0 min left\n",
      "Epoch [361/450], Loss: 346487.0438 about 90.0 min left\n",
      "Epoch [362/450], Loss: 344787.9625 about 89.0 min left\n",
      "Epoch [363/450], Loss: 342273.8063 about 88.0 min left\n",
      "Epoch [364/450], Loss: 340988.3688 about 87.0 min left\n",
      "Epoch [365/450], Loss: 342950.5000 about 86.0 min left\n",
      "Epoch [366/450], Loss: 342773.5500 about 85.0 min left\n",
      "Epoch [367/450], Loss: 349246.9750 about 84.0 min left\n",
      "Epoch [368/450], Loss: 336189.8563 about 83.0 min left\n",
      "Epoch [369/450], Loss: 334336.8000 about 82.0 min left\n",
      "Epoch [370/450], Loss: 328866.5312 about 81.0 min left\n",
      "Epoch [371/450], Loss: 325293.6500 about 80.0 min left\n",
      "Epoch [372/450], Loss: 318686.4813 about 79.0 min left\n",
      "Epoch [373/450], Loss: 315001.9750 about 78.0 min left\n",
      "Epoch [374/450], Loss: 311990.8563 about 77.0 min left\n",
      "Epoch [375/450], Loss: 307760.9625 about 76.0 min left\n",
      "Epoch [376/450], Loss: 305663.8656 about 75.0 min left\n",
      "Epoch [377/450], Loss: 301031.0344 about 74.0 min left\n",
      "Epoch [378/450], Loss: 301587.1875 about 73.0 min left\n",
      "Epoch [379/450], Loss: 290745.3063 about 72.0 min left\n",
      "Epoch [380/450], Loss: 286029.0281 about 71.0 min left\n",
      "Epoch [381/450], Loss: 282262.2625 about 70.0 min left\n",
      "Epoch [382/450], Loss: 294980.1312 about 69.0 min left\n",
      "Epoch [383/450], Loss: 277618.4781 about 68.0 min left\n",
      "Epoch [384/450], Loss: 268293.5656 about 67.0 min left\n",
      "Epoch [385/450], Loss: 269123.9188 about 66.0 min left\n",
      "Epoch [386/450], Loss: 258271.1750 about 65.0 min left\n",
      "Epoch [387/450], Loss: 251130.1500 about 64.0 min left\n",
      "Epoch [388/450], Loss: 244167.3750 about 63.0 min left\n",
      "Epoch [389/450], Loss: 243493.4125 about 62.0 min left\n",
      "Epoch [390/450], Loss: 230775.4969 about 61.0 min left\n",
      "Epoch [391/450], Loss: 225715.3906 about 60.0 min left\n",
      "Epoch [392/450], Loss: 219524.3625 about 59.0 min left\n",
      "Epoch [393/450], Loss: 212388.3625 about 58.0 min left\n",
      "Epoch [394/450], Loss: 205608.8094 about 57.0 min left\n",
      "Epoch [395/450], Loss: 195815.1437 about 56.0 min left\n",
      "Epoch [396/450], Loss: 191152.9250 about 55.0 min left\n",
      "Epoch [397/450], Loss: 183685.1094 about 54.0 min left\n",
      "Epoch [398/450], Loss: 183403.4813 about 53.0 min left\n",
      "Epoch [399/450], Loss: 164398.4094 about 52.0 min left\n",
      "Epoch [400/450], Loss: 158200.4594 about 51.0 min left\n",
      "Epoch [401/450], Loss: 157036.8922 about 50.0 min left\n",
      "Epoch [402/450], Loss: 152750.4234 about 49.0 min left\n",
      "Epoch [403/450], Loss: 140652.7906 about 48.0 min left\n",
      "Epoch [404/450], Loss: 143556.4312 about 47.0 min left\n",
      "Epoch [405/450], Loss: 137166.6656 about 46.0 min left\n",
      "Epoch [406/450], Loss: 128319.1000 about 45.0 min left\n",
      "Epoch [407/450], Loss: 110077.0734 about 44.0 min left\n",
      "Epoch [408/450], Loss: 102544.6047 about 43.0 min left\n",
      "Epoch [409/450], Loss: 97402.8844 about 42.0 min left\n",
      "Epoch [410/450], Loss: 91730.8172 about 41.0 min left\n",
      "Epoch [411/450], Loss: 86998.2422 about 40.0 min left\n",
      "Epoch [412/450], Loss: 82760.1562 about 39.0 min left\n",
      "Epoch [413/450], Loss: 80469.9578 about 38.0 min left\n",
      "Epoch [414/450], Loss: 73461.0844 about 37.0 min left\n",
      "Epoch [415/450], Loss: 70954.6242 about 36.0 min left\n",
      "Epoch [416/450], Loss: 67402.9648 about 35.0 min left\n",
      "Epoch [417/450], Loss: 69468.1820 about 34.0 min left\n",
      "Epoch [418/450], Loss: 61933.1219 about 33.0 min left\n",
      "Epoch [419/450], Loss: 60066.9992 about 32.0 min left\n",
      "Epoch [420/450], Loss: 59078.3727 about 31.0 min left\n",
      "Epoch [421/450], Loss: 52573.5398 about 30.0 min left\n",
      "Epoch [422/450], Loss: 50424.4211 about 29.0 min left\n",
      "Epoch [423/450], Loss: 50498.5477 about 28.0 min left\n",
      "Epoch [424/450], Loss: 48095.0813 about 27.0 min left\n",
      "Epoch [425/450], Loss: 47564.6465 about 26.0 min left\n",
      "Epoch [426/450], Loss: 45216.6031 about 25.0 min left\n",
      "Epoch [427/450], Loss: 45336.1977 about 24.0 min left\n",
      "Epoch [428/450], Loss: 42921.1555 about 23.0 min left\n",
      "Epoch [429/450], Loss: 42614.3063 about 22.0 min left\n",
      "Epoch [430/450], Loss: 41544.7289 about 21.0 min left\n",
      "Epoch [431/450], Loss: 40249.5992 about 20.0 min left\n",
      "Epoch [432/450], Loss: 39003.9375 about 19.0 min left\n",
      "Epoch [433/450], Loss: 39146.3039 about 18.0 min left\n",
      "Epoch [434/450], Loss: 41469.7520 about 17.0 min left\n",
      "Epoch [435/450], Loss: 42461.8273 about 16.0 min left\n",
      "Epoch [436/450], Loss: 40215.9516 about 15.0 min left\n",
      "Epoch [437/450], Loss: 40315.7125 about 14.0 min left\n",
      "Epoch [438/450], Loss: 39876.3688 about 13.0 min left\n",
      "Epoch [439/450], Loss: 38410.1703 about 12.0 min left\n",
      "Epoch [440/450], Loss: 35620.9477 about 11.0 min left\n",
      "Epoch [441/450], Loss: 34476.4938 about 10.0 min left\n",
      "Epoch [442/450], Loss: 34074.1094 about 9.0 min left\n",
      "Epoch [443/450], Loss: 33471.6434 about 8.0 min left\n",
      "Epoch [444/450], Loss: 31679.8328 about 7.0 min left\n",
      "Epoch [445/450], Loss: 31805.5648 about 6.0 min left\n",
      "Epoch [446/450], Loss: 31358.3906 about 5.0 min left\n",
      "Epoch [447/450], Loss: 31630.7715 about 4.0 min left\n",
      "Epoch [448/450], Loss: 30129.7203 about 3.0 min left\n",
      "Epoch [449/450], Loss: 31329.8215 about 2.0 min left\n",
      "Epoch [450/450], Loss: 30089.5809 about 1.0 min left\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 450\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\", 'about',(num_epochs-epoch)/1,'min left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './fan_corner3_detector_1127.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keep training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class FanDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_size=64):\n",
    "        self.annotations = pd.read_csv(annotations_file)\n",
    "        self.img_size = img_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.annotations.iloc[idx, 0]\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, (self.img_size, self.img_size)) / 2047.0  # Resize and normalize\n",
    "        image = image.reshape(1, self.img_size, self.img_size)  # Reshape for CNN input\n",
    "\n",
    "        # Label: x and y coordinates of the corner\n",
    "        label = self.annotations.iloc[idx, 1:3].values.astype(np.float32)\n",
    "        return torch.tensor(image, dtype=torch.float32), torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "# 使用自己的标注文件\n",
    "dataset = FanDataset('selected_points3_1127.csv')\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Loss and optimizer\u001b[39;00m\n\u001b[0;32m      4\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Loss and optimizer\u001b[39;00m\n\u001b[0;32m      4\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\raykuo7\\.conda\\envs\\tvdi\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\raykuo7\\.conda\\envs\\tvdi\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 450\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\", 'about',(num_epochs-epoch)/1,'min left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './fan_corner_detector_1127.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvdi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
